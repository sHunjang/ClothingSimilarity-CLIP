import os
import torch
import clip
from PIL import Image
from tqdm import tqdm
from collections import defaultdict

# ì„¤ì •
device = "cuda" if torch.cuda.is_available() else "cpu"

#clip.load(): OpenAIì—ì„œ í•™ìŠµëœ CLIP ëª¨ë¸ ì „ì²˜ë¦¬ì™€ ì „ì²˜ë¦¬ í•¨ìˆ˜ Load
model, preprocess = clip.load("ViT-B/32", device=device)    # ViT-B/32 : Vision Transformer ê¸°ë°˜ CLIP ëª¨ë¸


# ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë„£ê¸° ì „ì— ì „ì²˜ë¦¬ ê³¼ì • í•¨ìˆ˜ (224x224ë¡œ ì‚¬ì´ì¦ˆ ì¡°ì •, ì •ê·œí™” ë“±)
def get_image_feature(image_path):
    image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)
    with torch.no_grad():
        feature = model.encode_image(image)     # encode_image(): CLIPì´ ì´ë¯¸ì§€ -> ë²¡í„°(512ì°¨ì›)ë¡œ ë³€í™˜
        feature = feature / feature.norm(dim=-1, keepdim=True)      # Cosine Similarityë¥¼ ìœ„í•´ ì •ê·œí™”(norm=1)
    return feature.to("cpu")    # ì´í›„ ì—°ì‚°ì˜ ì•ˆì •ì„±ì„ ìœ„í•´ "CPU"ë¡œ ì´ë™


# Dataset í•˜ìœ„ í´ë”ë“¤(T-shirt, Hoodie, Jeans, ..)ì„ í´ë˜ìŠ¤(Class)ë¡œ ê°„ì£¼
def load_dataset_features(dataset_root):
    features = []   # ì„ë² ë”© ë²¡í„°
    labels = []     # í´ë˜ìŠ¤ëª… (ex. hoodie, jeans, ..)
    paths = []      # ì‹¤ì œ íŒŒì¼ ê²½ë¡œ
    for class_folder in os.listdir(dataset_root):
        class_path = os.path.join(dataset_root, class_folder)
        if not os.path.isdir(class_path): continue
        for file in os.listdir(class_path):
            if file.lower().endswith(('.jpg', '.png')):
                path = os.path.join(class_path, file)
                feature = get_image_feature(path)
                features.append(feature)
                labels.append(class_folder)  # í´ë˜ìŠ¤ëª… ì €ì¥, ì •ë‹µ ë¼ë²¨
                paths.append(path)
    return torch.cat(features), labels, paths   # torch.cat(features) ë¡œ ë²¡í„°ë“¤ì„ [N, 512] í…ì„œë¡œ ë¬¶ì–´ ë°˜í™˜


# Query ë²¡í„°ì™€ ëª¨ë“  ë°ì´í„°ì…‹ ì´ë¯¸ì§€ ë²¡í„° ê°„ Cosine Similarity ê³„ì‚°
def get_topk_similar(query_feature, dataset_features, labels, paths, k=5):

    scores = (dataset_features @ query_feature.T).squeeze(1)
    # (dataset_features @ query_feature.T): ë²¡í„° ë‚´ì  = Cosine Simialrity -> ë²¡í„° ì •ê·œí™” í–ˆê¸° ë•Œë¬¸

    topk = scores.topk(k).indices.tolist()  # topk(): ìœ ì‚¬ë„ ë†’ì€ ìˆœì„œëŒ€ë¡œ Kê°œ ì¶”ì¶œ
    return [(paths[i], labels[i], scores[i].item()) for i in topk]  # [(ê²½ë¡œ, í´ë˜ìŠ¤, ìœ ì‚¬ë„)] ìˆœìœ¼ë¡œ ì¶œë ¥ë¨.


# ì¿¼ë¦¬ ì´ë¯¸ì§€ íŒŒì¼ëª…ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë‹µ class ì¶”ì¶œ (ex. Hoodie_01.jpg -> hoodie)
# Top-K ê²°ê³¼ ì¤‘ì—ì„œ ì •ë‹µ Classê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
# ì „ì²´ ì¿¼ë¦¬ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ Accuracy ê³„ì‚°
def evaluate(query_folder, dataset_root, k=5):
    dataset_features, dataset_labels, dataset_paths = load_dataset_features(dataset_root)
    correct = 0
    total = 0

    for file in tqdm(os.listdir(query_folder)):
        if not file.lower().endswith(('.jpg', '.png')): continue
        query_path = os.path.join(query_folder, file)
        query_feature = get_image_feature(query_path)

        # ì •ë‹µ í´ë˜ìŠ¤ëª… ì¶”ì¶œ ex: "hoodie_01.jpg"
        gt_class = file.split("_")[0]  # ex: hoodie

        topk = get_topk_similar(query_feature, dataset_features, dataset_labels, dataset_paths, k)

        predicted_classes = [label for _, label, _ in topk]
        if gt_class in predicted_classes:
            correct += 1
        total += 1

        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ” Query: {file} | ì •ë‹µ: {gt_class}")
        for i, (path, label, score) in enumerate(topk):
            print(f"  {i+1}. {label} ({score:.4f}) - {os.path.basename(path)}")

    acc = correct / total if total else 0
    print(f"\nâœ… Top-{k} Accuracy: {acc:.2%} ({correct}/{total})")



if __name__ == "__main__":
    # ìƒì˜ ê¸°ì¤€ ì‹¤í—˜
    evaluate("queries/tops", "dataset/tops", k=5)